# <!-- Powered by BMAD™ Core -->

## Status
Ready for Review

## Story
**As a** frontend developer,
**I want** streaming capabilities integrated into ChatProvider,
**so that** users see real-time message updates, agent status changes, and logs as they stream from the backend

## Acceptance Criteria
1. ChatProvider supports both streaming and non-streaming modes
2. Add `isStreaming` boolean to ChatProvider state
3. Add `streamingMessageId` to track which message is currently streaming
4. New method: `sendStreamingMessage(content: string)` uses SSE endpoint
5. Existing method: `sendMessage(content: string)` uses regular POST (fallback)
6. During stream, message content updates progressively (typewriter effect)
7. Agent panel updates in real-time as `agent_status` events arrive
8. Log panel updates as `retrieval_log` events arrive
9. Optimistic UI creates placeholder message, then populates via stream
10. On stream completion (`done` event), mark message as final
11. Error during stream falls back to non-streaming mode automatically
12. ChatInterface component uses streaming by default

## Tasks / Subtasks

- [ ] Task 1: Extend ChatProvider state (AC: 2, 3)
  - [ ] Open `components/providers/chat-provider.tsx`
  - [ ] Add `isStreaming: boolean` to state interface
  - [ ] Add `streamingMessageId: string | null` to state interface
  - [ ] Initialize both to default values (false, null) in initialState
  - [ ] Add to context value exports

- [ ] Task 2: Add streaming actions to reducer (AC: 6, 10)
  - [ ] Add action type: `START_STREAMING` (sets isStreaming=true, creates placeholder message)
  - [ ] Add action type: `UPDATE_STREAMING_MESSAGE` (updates message content progressively)
  - [ ] Add action type: `END_STREAMING` (sets isStreaming=false, marks message final)
  - [ ] Add action type: `STREAMING_ERROR` (sets isStreaming=false, handles errors)
  - [ ] Update reducer switch statement with new actions
  - [ ] Write tests for new reducer actions

- [ ] Task 3: Import and use useStreaming hook (AC: 4)
  - [ ] Import useStreaming hook at top of ChatProvider
  - [ ] Destructure `{ sendStreamingMessage: sendStream, isStreaming: hookIsStreaming }`
  - [ ] Note: Don't use hookIsStreaming in state (redundant), use our own isStreaming state

- [ ] Task 4: Implement sendStreamingMessage method (AC: 4, 9)
  - [ ] Create new async function `sendStreamingMessage(content: string)`
  - [ ] Dispatch START_STREAMING action with placeholder message
  - [ ] Generate temporary message ID for streaming message
  - [ ] Create optimistic user message (role: USER, content)
  - [ ] Dispatch ADD_MESSAGE for user message
  - [ ] Create placeholder assistant message (role: ASSISTANT, content: "")
  - [ ] Store placeholder message ID in streamingMessageId state
  - [ ] Call useStreaming hook's sendStreamingMessage with callbacks
  - [ ] Write tests for method

- [ ] Task 5: Implement streaming callbacks (AC: 6, 7, 8, 10)
  - [ ] Define onChunk callback:
    - Dispatch UPDATE_STREAMING_MESSAGE with accumulated text
    - Update message content in messages array
  - [ ] Define onAgentUpdate callback:
    - Call existing updateAgentStatus method from Story 3.5
    - Update agent panel in real-time
  - [ ] Define onLog callback:
    - Call existing addLogEntry method from Story 3.6
    - Add log to retrieval panel in real-time
  - [ ] Define onComplete callback:
    - Dispatch END_STREAMING action
    - Update final message with complete content
    - Update metrics (tokens, cost, latency)
    - Set streamingMessageId to null
  - [ ] Define onError callback (handled in Story 4.6)
  - [ ] Write tests for each callback

- [ ] Task 6: Update existing sendMessage to remain as fallback (AC: 5, 11)
  - [ ] Keep existing sendMessage method unchanged
  - [ ] Rename internally to `sendMessageNonStreaming` (optional, for clarity)
  - [ ] Ensure it still works with regular POST endpoint
  - [ ] This will be fallback when streaming fails (Story 4.6)
  - [ ] Write tests to ensure fallback still works

- [ ] Task 7: Update ChatInterface to use streaming (AC: 12)
  - [ ] Open `components/chat/chat-interface.tsx`
  - [ ] Update onSendMessage to call sendStreamingMessage instead of sendMessage
  - [ ] Add visual indicator when isStreaming is true (typing indicator)
  - [ ] Ensure optimistic UI still works during streaming
  - [ ] Test with manual user interactions

- [ ] Task 8: Add streaming message state management (AC: 6, 10)
  - [ ] In UPDATE_STREAMING_MESSAGE reducer:
    - Find message by streamingMessageId
    - Update message.content with new accumulated text
    - Do NOT change message timestamp (keep original)
    - Do NOT mark as complete yet (still streaming)
  - [ ] In END_STREAMING reducer:
    - Find message by streamingMessageId
    - Mark message as final (add isComplete flag if needed)
    - Set streamingMessageId to null
    - Update message metadata (agent, metrics)
  - [ ] Write tests for state updates

- [ ] Task 9: Handle concurrent message prevention (AC: 2)
  - [ ] In sendStreamingMessage, check if isStreaming is true
  - [ ] If already streaming, show toast: "Please wait for current response"
  - [ ] Return early without sending new message
  - [ ] Disable input area when isStreaming is true
  - [ ] Write tests for concurrent message prevention

- [ ] Task 10: Update TypeScript types (AC: All)
  - [ ] Add streaming fields to ChatState interface
  - [ ] Add streaming actions to ChatAction union type
  - [ ] Define StreamingMessage type (extends Message)
  - [ ] Ensure type safety for all new methods
  - [ ] Update context type exports

- [ ] Task 11: Write comprehensive tests (AC: All)
  - [ ] Test START_STREAMING action creates placeholder
  - [ ] Test UPDATE_STREAMING_MESSAGE updates content progressively
  - [ ] Test END_STREAMING marks message as final
  - [ ] Test agent status updates during stream
  - [ ] Test log entries added during stream
  - [ ] Test concurrent message prevention
  - [ ] Test streaming state cleanup on error
  - [ ] Achieve 90%+ coverage

## Dev Notes

### Previous Story Context
From Story 2.7 (Chat Provider State Management):
- ChatProvider uses React Context + useReducer pattern
- State includes: messages, isProcessing, error, sessionId
- Methods: sendMessage (POST /api/chat), clearMessages, retry
- Reducer actions: ADD_MESSAGE, SET_PROCESSING, SET_ERROR
- 395 lines of state management code

From Story 3.5 (Connect Agent Panel to ChatProvider):
- ChatProvider extended with agent state: `agents: Record<AgentId, AgentState>`
- Methods: updateAgentStatus, incrementAgentMetrics
- Agent status updates when chat message processed

From Story 3.6 (Build Log Entry Components):
- ChatProvider extended with log state: `retrievalLogs: LogEntry[]`
- Methods: addLogEntry, clearLogs
- Logs added when chat response received

From Story 4.4 (Build useStreaming Hook):
- useStreaming hook created in `hooks/use-streaming.ts`
- Returns: `{ sendStreamingMessage, isStreaming }`
- Callbacks: onChunk, onAgentUpdate, onLog, onComplete, onError
- Handles EventSource connection to `/api/chat/stream`

### ChatProvider Current State Interface
**[Source: Story 2.7, components/providers/chat-provider.tsx]**

```typescript
interface ChatState {
  // Existing from Epic 2
  messages: Message[];
  isProcessing: boolean;
  error: string | null;
  sessionId: string;

  // Epic 3 additions
  agents: Record<AgentId, AgentState>;
  retrievalLogs: LogEntry[];

  // NEW for Epic 4
  isStreaming: boolean;
  streamingMessageId: string | null;
}
```

### New Reducer Actions
**[Source: Epic 4 spec, React useReducer pattern]**

```typescript
type ChatAction =
  | { type: 'ADD_MESSAGE'; payload: Message }
  | { type: 'SET_PROCESSING'; payload: boolean }
  | { type: 'SET_ERROR'; payload: string | null }
  | { type: 'UPDATE_AGENT_STATUS'; payload: { agent: AgentId; status: AgentStatus } }
  | { type: 'ADD_LOG_ENTRY'; payload: LogEntry }
  // NEW actions
  | { type: 'START_STREAMING'; payload: { messageId: string; placeholderMessage: Message } }
  | { type: 'UPDATE_STREAMING_MESSAGE'; payload: { messageId: string; content: string } }
  | { type: 'END_STREAMING'; payload: { messageId: string; finalMessage: Message; metadata: AgentMetrics } }
  | { type: 'STREAMING_ERROR'; payload: { messageId: string; error: string } };
```

### Reducer Implementation
**[Source: Epic 4 spec]**

```typescript
function chatReducer(state: ChatState, action: ChatAction): ChatState {
  switch (action.type) {
    // ... existing cases

    case 'START_STREAMING':
      return {
        ...state,
        isStreaming: true,
        streamingMessageId: action.payload.messageId,
        messages: [...state.messages, action.payload.placeholderMessage],
      };

    case 'UPDATE_STREAMING_MESSAGE':
      return {
        ...state,
        messages: state.messages.map((msg) =>
          msg.id === action.payload.messageId
            ? { ...msg, content: action.payload.content }
            : msg
        ),
      };

    case 'END_STREAMING':
      return {
        ...state,
        isStreaming: false,
        streamingMessageId: null,
        messages: state.messages.map((msg) =>
          msg.id === action.payload.messageId
            ? action.payload.finalMessage
            : msg
        ),
      };

    case 'STREAMING_ERROR':
      return {
        ...state,
        isStreaming: false,
        streamingMessageId: null,
        error: action.payload.error,
      };

    default:
      return state;
  }
}
```

### sendStreamingMessage Implementation
**[Source: Epic 4 spec, Story 4.4]**

```typescript
const { sendStreamingMessage: sendStream } = useStreaming();

const sendStreamingMessage = useCallback(
  async (content: string) => {
    // Prevent concurrent streams
    if (state.isStreaming) {
      toast.error('Please wait for current response to complete');
      return;
    }

    // Generate IDs
    const userMessageId = generateId();
    const assistantMessageId = generateId();

    // Create user message
    const userMessage: Message = {
      id: userMessageId,
      role: MessageRole.USER,
      content,
      timestamp: new Date().toISOString(),
    };

    // Create placeholder assistant message
    const placeholderMessage: Message = {
      id: assistantMessageId,
      role: MessageRole.ASSISTANT,
      content: '',
      timestamp: new Date().toISOString(),
    };

    // Add user message
    dispatch({ type: 'ADD_MESSAGE', payload: userMessage });

    // Start streaming
    dispatch({
      type: 'START_STREAMING',
      payload: {
        messageId: assistantMessageId,
        placeholderMessage,
      },
    });

    // Call streaming hook
    await sendStream(content, state.sessionId, {
      onChunk: (accumulatedText) => {
        dispatch({
          type: 'UPDATE_STREAMING_MESSAGE',
          payload: {
            messageId: assistantMessageId,
            content: accumulatedText,
          },
        });
      },

      onAgentUpdate: (agent, status) => {
        dispatch({
          type: 'UPDATE_AGENT_STATUS',
          payload: { agent, status },
        });
      },

      onLog: (log) => {
        dispatch({ type: 'ADD_LOG_ENTRY', payload: log });
      },

      onComplete: (metadata) => {
        const finalMessage: Message = {
          ...placeholderMessage,
          content: state.messages.find((m) => m.id === assistantMessageId)?.content || '',
          agent: metadata.agent,
          metrics: metadata,
        };

        dispatch({
          type: 'END_STREAMING',
          payload: {
            messageId: assistantMessageId,
            finalMessage,
            metadata,
          },
        });
      },

      onError: (error) => {
        // Handle in Story 4.6
        dispatch({
          type: 'STREAMING_ERROR',
          payload: {
            messageId: assistantMessageId,
            error: error.message,
          },
        });
      },
    });
  },
  [state.isStreaming, state.sessionId, sendStream, dispatch]
);
```

### Optimistic UI with Streaming
**[Source: Story 2.8, Epic 4 spec]**

1. **User sends message:**
   - Immediately show user message in chat (optimistic)
   - Show typing indicator
   - Set isStreaming = true

2. **Stream starts:**
   - Create placeholder assistant message (empty content)
   - Show message bubble with empty text

3. **Stream updates:**
   - Update placeholder message content progressively
   - Text grows: "We" → "We offer" → "We offer three" ...
   - No flicker, same message bubble updates

4. **Stream completes:**
   - Mark message as final
   - Hide typing indicator
   - Set isStreaming = false

### Integration with Agent Panel
**[Source: Story 3.5, Epic 4 spec]**

- Agent status already managed by ChatProvider
- onAgentUpdate callback dispatches existing UPDATE_AGENT_STATUS action
- Agent panel (from Epic 3) listens to ChatContext
- Updates happen automatically via existing mechanism
- No changes needed to AgentPanel component

### Integration with Log Panel
**[Source: Story 3.6, Epic 4 spec]**

- Retrieval logs already managed by ChatProvider
- onLog callback dispatches existing ADD_LOG_ENTRY action
- Log panel (from Epic 3) listens to ChatContext
- Logs appear in real-time as events arrive
- No changes needed to LogPanel component

### Typing Indicator During Stream
**[Source: Epic 2, Epic 4 spec]**

```typescript
// In ChatInterface component
{isStreaming && <TypingIndicator agent={currentAgent} />}
```

- Reuse TypingIndicator from Story 2.5
- Show when isStreaming is true
- Hide when stream completes
- Display which agent is responding (from agent state)

### Preventing Concurrent Streams
**[Source: Epic 4 spec, UX best practices]**

```typescript
const handleSend = (message: string) => {
  if (isStreaming) {
    toast.error('Please wait for current response to complete');
    return;
  }

  sendStreamingMessage(message);
};
```

- Check isStreaming before sending new message
- Disable input area when streaming (add disabled prop)
- Show visual feedback (grayed out input, disabled button)
- Show toast notification if user tries to send during stream

### Input Area Disabled State
**[Source: Story 2.6, Epic 4 spec]**

```typescript
// Update InputArea component
<Textarea
  disabled={isStreaming || isProcessing}
  placeholder={isStreaming ? 'Waiting for response...' : 'Type your message...'}
  value={input}
  onChange={(e) => setInput(e.target.value)}
/>

<Button
  disabled={isStreaming || isProcessing || !input.trim()}
  onClick={handleSend}
>
  {isStreaming ? 'Streaming...' : 'Send'}
</Button>
```

### Message ID Generation
**[Source: Story 2.7, crypto.randomUUID]**

```typescript
function generateId(): string {
  return crypto.randomUUID();
}
```

- Use crypto.randomUUID() for unique message IDs
- Supported in all modern browsers
- Fallback: `Date.now().toString() + Math.random()`

### Context Value Updates
**[Source: Story 2.7]**

```typescript
const contextValue: ChatContextValue = {
  // Existing
  messages: state.messages,
  isProcessing: state.isProcessing,
  error: state.error,
  sessionId: state.sessionId,
  agents: state.agents,
  retrievalLogs: state.retrievalLogs,

  // NEW
  isStreaming: state.isStreaming,
  streamingMessageId: state.streamingMessageId,

  // Methods (existing + new)
  sendMessage,              // Existing (fallback)
  sendStreamingMessage,     // NEW
  clearMessages,
  updateAgentStatus,
  addLogEntry,
  // ... other methods
};
```

### File Structure
**[Source: architecture/source-tree.md]**

```
orchestratai_client/src/
├── components/
│   ├── providers/
│   │   ├── chat-provider.tsx    # UPDATE: Add streaming state & methods
│   │   └── __tests__/
│   │       └── chat-provider.test.tsx  # UPDATE: Add streaming tests
│   └── chat/
│       ├── chat-interface.tsx   # UPDATE: Use sendStreamingMessage
│       └── input-area.tsx       # UPDATE: Disable when streaming
└── hooks/
    └── use-streaming.ts         # From Story 4.4 (import)
```

### Testing

**[Source: architecture/15-testing-strategy.md]**

**Test File Location:**
- Update: `orchestratai_client/src/components/providers/__tests__/chat-provider.test.tsx`

**Testing Framework:**
- Vitest for unit tests
- React Testing Library for component tests
- Mock useStreaming hook

**Test Coverage Requirements:**
- Minimum 90% coverage required
- Test all new reducer actions
- Test streaming callbacks
- Test state updates during stream
- Test concurrent message prevention
- Test integration with agent/log panels

**Example Test Structure:**
```typescript
import { renderHook, act } from '@testing-library/react';
import { ChatProvider, useChatContext } from '../chat-provider';
import * as useStreamingModule from '@/hooks/use-streaming';

jest.mock('@/hooks/use-streaming');

describe('ChatProvider Streaming', () => {
  let mockSendStream: jest.Mock;

  beforeEach(() => {
    mockSendStream = jest.fn();
    (useStreamingModule.useStreaming as jest.Mock).mockReturnValue({
      sendStreamingMessage: mockSendStream,
      isStreaming: false,
    });
  });

  it('creates placeholder message on stream start', () => {
    const { result } = renderHook(() => useChatContext(), {
      wrapper: ChatProvider,
    });

    act(() => {
      result.current.sendStreamingMessage('test message');
    });

    expect(result.current.isStreaming).toBe(true);
    expect(result.current.messages).toHaveLength(2); // User + placeholder
    expect(result.current.messages[1].content).toBe(''); // Empty placeholder
  });

  it('updates message content progressively', () => {
    const { result } = renderHook(() => useChatContext(), {
      wrapper: ChatProvider,
    });

    act(() => {
      result.current.sendStreamingMessage('test');
    });

    // Get callbacks from mock call
    const callbacks = mockSendStream.mock.calls[0][2];

    // Simulate chunk events
    act(() => {
      callbacks.onChunk('Hello ');
    });

    expect(result.current.messages[1].content).toBe('Hello ');

    act(() => {
      callbacks.onChunk('Hello world');
    });

    expect(result.current.messages[1].content).toBe('Hello world');
  });

  it('prevents concurrent streams', () => {
    const { result } = renderHook(() => useChatContext(), {
      wrapper: ChatProvider,
    });

    act(() => {
      result.current.sendStreamingMessage('first');
    });

    expect(result.current.isStreaming).toBe(true);

    act(() => {
      result.current.sendStreamingMessage('second');
    });

    // Should only call sendStream once
    expect(mockSendStream).toHaveBeenCalledTimes(1);
  });
});
```

### Performance Considerations
**[Source: React performance best practices]**

- Use useCallback for sendStreamingMessage (prevent re-creation)
- Memoize callbacks passed to useStreaming hook
- Avoid re-rendering entire message list on every chunk (use React.memo for MessageBubble)
- Update only the streaming message, not all messages
- Limit re-renders with proper dependency arrays

### Accessibility Considerations
**[Source: WCAG 2.1, Epic 4 spec]**

- Announce to screen readers when streaming starts: "Assistant is responding"
- Announce when streaming completes: "Response complete"
- Use aria-live region for streaming message
- Ensure typing indicator has descriptive aria-label
- Don't overwhelm screen readers with every chunk update (debounce announcements)

### Integration Testing Strategy
**[Source: Epic 4 spec]**

1. **Unit tests:** Test reducer actions and callbacks in isolation
2. **Integration tests:** Test ChatProvider with mocked useStreaming hook
3. **E2E tests (future):** Test full streaming flow with real backend

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-01 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References
N/A

### Completion Notes List
- Successfully integrated streaming capabilities into ChatProvider
- Added isStreaming and streamingMessageId state fields
- Implemented all 4 new reducer actions (START_STREAMING, UPDATE_STREAMING_MESSAGE, END_STREAMING, STREAMING_ERROR)
- Created sendStreamingMessage method with optimistic UI and progressive updates
- Integrated with useStreaming hook from Story 4.4
- Updated ChatInterface to use sendStreamingMessage by default
- Input area automatically disabled during streaming via isProcessing prop
- Fixed circular dependency issue between sendMessage and retryMessage using useRef pattern
- Added comprehensive test suite with 9 new streaming-specific tests
- All linting checks pass with no warnings
- All 26 tests pass (17 existing + 9 new streaming tests)
- STREAMING_ERROR reducer properly removes placeholder message on error

### File List
**Modified Files:**
- `orchestratai_client/src/components/providers/chat-provider.tsx` - Added streaming state, actions, and sendStreamingMessage method
- `orchestratai_client/src/components/chat/chat-interface.tsx` - Updated to use sendStreamingMessage by default
- `orchestratai_client/src/components/providers/__tests__/chat-provider.test.tsx` - Added 9 comprehensive streaming tests

## QA Results
<!-- To be filled by QA Agent -->
