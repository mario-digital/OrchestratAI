# <!-- Powered by BMAD™ Core -->

## Status
Ready for development

## Story
**As a** frontend developer,
**I want** existing UI components connected to real agent data via SSE streaming,
**so that** users see live metrics, retrieval logs, and execution graphs without any UI design changes

## Acceptance Criteria
1. All 14 existing panel components work with real data
2. No UI design changes or new components added
3. SSE streaming shows real-time updates
4. Agent metrics display real values (not mocks)
5. Retrieval panel shows real documents from ChromaDB
6. Execution graph shows real LangGraph workflow
7. Cache hit/miss indicators show real cache status
8. Error states handled gracefully
9. Manual QA confirms all features working

## Tasks / Subtasks

[x] Task 1: Verify SSE event handlers (AC: 3)
  - [x] Open `orchestratai_client/src/hooks/use-streaming.ts`
  - [x] Review existing event handling logic
  - [x] Verify event types match backend SSE messages:
    - `agent_status`
    - `retrieval_log`
    - `message_chunk`
    - `done`
  - [x] No changes needed if event types already match
  - [x] If mismatches found, update event type handling
  - [x] Ensure error events handled gracefully

- [ ] Task 2: Test AgentPanel with real data (AC: 1, 4)
  - [ ] Open `orchestratai_client/src/components/panels/agent-panel.tsx`
  - [ ] Review component props and data structure
  - [ ] Manual test with real backend:
    - Send query: "What is RAG?"
    - Verify Orchestrator status appears
    - Verify RAG agent status appears
    - Verify status badges update (Idle → Processing → Complete)
  - [ ] Verify agent names display correctly
  - [ ] Verify timestamps update in real-time

- [ ] Task 3: Test AgentMetrics with real data (AC: 4)
  - [ ] Open `orchestratai_client/src/components/metrics/agent-metrics.tsx`
  - [ ] Manual test metrics display:
    - Verify real token counts (input + output)
    - Verify real cost values (e.g., "$0.0405")
    - Verify real latency values (e.g., "2,800ms")
  - [ ] Test with different agents:
    - Orchestrator: ~200 tokens, ~$0.0006
    - RAG: ~3,500 tokens, ~$0.04
    - CAG (hit): 0 tokens, $0.00
    - CAG (miss): ~400 tokens, ~$0.0004
  - [ ] Verify cost formatting (2-4 decimal places)
  - [ ] Verify latency formatting (ms or s)

- [ ] Task 4: Test RetrievalPanel with real documents (AC: 5)
  - [ ] Open `orchestratai_client/src/components/panels/retrieval-panel.tsx`
  - [ ] Manual test document display:
    - Send query triggering RAG agent
    - Verify 5 documents appear in panel
    - Verify each document shows:
      - Source filename
      - Page number
      - Similarity score (0.0-1.0)
      - Content preview
  - [ ] Click document to open modal
  - [ ] Verify DocumentModal shows full content
  - [ ] Test with different query types:
    - RAG query: Shows vector search logs
    - CAG query: Shows cache logs
    - Hybrid query: Shows both

- [ ] Task 5: Test ExecutionGraph with real workflow (AC: 6)
  - [ ] Open `orchestratai_client/src/components/graphs/execution-graph.tsx`
  - [ ] Manual test graph display:
    - Send query: "What is RAG?"
    - Verify nodes appear: analyse → route → vector_search → generate
    - Verify nodes highlight as they execute
    - Verify final state shows all nodes complete
  - [ ] Test with different routes:
    - Meta query (guide mode): analyse → guide → done
    - Domain query (RAG): analyse → route → rag → done
    - Policy query (CAG): analyse → route → cag → done
  - [ ] Verify graph layout is readable
  - [ ] Verify timing information shows on nodes

- [ ] Task 6: Test DocumentModal with real content (AC: 5)
  - [ ] Open `orchestratai_client/src/components/modals/document-modal.tsx`
  - [ ] Manual test modal:
    - Click document in retrieval panel
    - Verify modal opens
    - Verify full document content displays
    - Verify metadata shows (source, page, score)
    - Verify close button works
  - [ ] Test with PDF documents
  - [ ] Test with Markdown documents
  - [ ] Test with JSON documents

- [ ] Task 7: Test CacheOperationCard with real cache status (AC: 7)
  - [ ] Open `orchestratai_client/src/components/cards/cache-operation-card.tsx`
  - [ ] Manual test cache indicators:
    - First query: "Can I get a refund?"
    - Verify shows "MISS" indicator
    - Send same query again
    - Verify shows "HIT" indicator
  - [ ] Verify cache metrics:
    - Hit: Shows saved cost, similarity score
    - Miss: Shows cache lookup time
  - [ ] Test cache card styling (green for hit, gray for miss)

- [ ] Task 8: Test remaining specialized cards (AC: 1, 4, 5, 6)
  - [ ] Test VectorSearchCard (in `components/panels/vector-search-card.tsx`):
    - Verify shows similarity scores
    - Verify shows top-k value (e.g., "Top 5 results")
    - Verify highlights best match
  - [ ] Test QueryAnalysisCard (in `components/cards/query-analysis-card.tsx`):
    - Verify shows intent classification
    - Verify shows confidence score
    - Verify shows routing decision
    - Verify shows fallback chain if present
  - [ ] Test all log entry components:
    - Verify VECTOR_SEARCH logs render correctly
    - Verify CACHE logs render correctly
    - Verify ROUTING logs render correctly
  - [ ] Verify all cards use real data (no hardcoded mocks)

- [ ] Task 9: Test ChatProvider integration (AC: 3, 8)
  - [ ] Open `orchestratai_client/src/providers/chat-provider.tsx`
  - [ ] Review ChatProvider state management
  - [ ] Manual test:
    - Send message
    - Verify optimistic UI update (message appears immediately)
    - Verify SSE events update state in real-time
    - Verify final ChatResponse updates message
  - [ ] Test error handling:
    - Stop backend
    - Send message
    - Verify error message displays
    - Verify no crash/infinite loading
  - [ ] Test message history:
    - Send multiple messages
    - Verify history persists
    - Verify context sent to backend

- [ ] Task 10: Test SSE streaming end-to-end (AC: 3)
  - [ ] Manual test streaming flow:
    - Open browser DevTools Network tab
    - Send query
    - Verify SSE connection established
    - Verify events stream in order:
      1. `agent_status` (Orchestrator analyzing)
      2. `agent_status` (Worker processing)
      3. `retrieval_log` (Documents found)
      4. `message_chunk` (Response streaming)
      5. `done` (Final response)
  - [ ] Verify UI updates match event order
  - [ ] Verify no duplicate events
  - [ ] Verify connection closes properly on completion

- [ ] Task 11: Update environment configuration (AC: 2)
  - [ ] Open `orchestratai_client/.env.local`
  - [ ] Verify `NEXT_PUBLIC_API_URL` points to backend
  - [ ] Default: `http://localhost:8000`
  - [ ] No code changes needed - just verify env var used
  - [ ] Document in README if not already

- [ ] Task 12: Manual QA testing (AC: 9)
  - [ ] Test all 4 agent types:
    - **Meta query**: "What can you help with?"
      - Verify guide mode (orchestrator only)
      - Verify no retrieval logs
    - **Domain query**: "What is RAG?"
      - Verify RAG agent invoked
      - Verify 5 documents retrieved
      - Verify similarity scores shown
    - **Policy query**: "Can I get a refund?"
      - First time: Verify CAG miss
      - Second time: Verify CAG hit
      - Verify cost savings shown
    - **Complex query**: "Compare RAG and CAG and explain when to use each"
      - Verify Hybrid agent invoked
      - Verify both vector search + cache logs
      - Verify sources_used > 1
    - **Simple chat**: "Hello!"
      - Verify Direct agent invoked
      - Verify fast response (<1s)
      - Verify low cost
  - [ ] Test guide mode vs delegate mode
  - [ ] Test cache hits show correctly
  - [ ] Test fallback scenarios:
    - Simulate ChromaDB failure
    - Verify graceful degradation
    - Verify error message to user
  - [ ] Document all findings in QA notes

- [ ] Task 13: Cross-browser testing (AC: 9)
  - [ ] Test on Chrome (desktop)
  - [ ] Test on Safari (desktop)
  - [ ] Test on Firefox
  - [ ] Test on Chrome (mobile)
  - [ ] Test on Safari (iOS)
  - [ ] Verify SSE works on all browsers
  - [ ] Verify no visual regressions
  - [ ] Document any browser-specific issues

## Dev Notes

### Architecture Context
**[Source: docs/agent-planning/agent-feature-planning.md, Story 7.6]**

Connect existing frontend components to real agent data via SSE streaming. No UI design changes - just wire real data to existing panels. Verify all 14 panel components display real metrics, logs, and execution graphs.

### Zero UI Changes Philosophy
**[Source: agent-feature-planning.md:30-35]**

✅ **Zero UI Design Changes**
- Existing 14 panel components already built and perfect
- Simply swap mock data for real data
- Same API contracts maintained
- No new components needed

### Existing Components (Already Built)
**[Source: agent-feature-planning.md:98-103]**

```
┌────────────┐  ┌─────────────┐  ┌──────────────┐
│ Agent      │  │ Retrieval   │  │ Execution    │
│ Panel      │  │ Panel       │  │ Graph        │
│ (138 lines)│  │ (385 lines) │  │ (219 lines)  │  14 Panels Ready
└────────────┘  └─────────────┘  └──────────────┘
```

All components already consume `ChatResponse` schema - just need real data instead of mocks.

### SSE Event Flow
**[Source: agent-feature-planning.md:105-110]**

```
SSE Streaming
(use-streaming.ts)
524 lines - Ready
```

The `useStreaming` hook already handles all event types. No changes needed if backend emits matching events.

### Expected Event Order
**[Source: agent-feature-planning.md:179-209]**

For query: "What is RAG?"

1. `agent_status`: Orchestrator analyzing (status: "processing")
2. `agent_status`: RAG agent processing (status: "processing")
3. `retrieval_log`: Vector search results (5 documents)
4. `message_chunk`: Response text streaming
5. `message_chunk`: More response text
6. `done`: Final ChatResponse with all metrics

### ChatResponse Schema
**[Source: orchestratai_api/src/models/chat.py]**

Frontend expects this exact schema (already defined):

```typescript
interface ChatResponse {
  id: string;
  message: string;
  agents: AgentStatus[];
  agent_metrics: AgentMetrics;
  retrieval_logs: RetrievalLog[];
  execution_graph: ExecutionGraph;
  metadata: Record<string, any>;
}
```

Backend (from Story 7.3) already returns this schema - no changes needed.

### Real Data Examples
**[Source: agent-feature-planning.md:199-203]**

**Metrics Automatically Returned:**
- Orchestrator: 200 tokens, $0.0006, 800ms (Bedrock Sonnet)
- RAG Agent: 3,500 tokens, $0.0405, 2,800ms (OpenAI GPT-4)
- **Total: $0.0411, 3,600ms, 5 documents retrieved**

**Existing UI Automatically Shows:**
- Agent Panel: "Orchestrator → RAG" (no changes needed)
- Retrieval Panel: 5 documents with real similarity scores
- Execution Graph: analyze_query → route → vector_search → generate
- Metrics Panel: Real tokens, real cost, real latency

### Component Locations
**[Source: architecture/source-tree.md]**

```
orchestratai_client/src/
├── hooks/
│   └── use-streaming.ts          # Already handles SSE events
├── components/
│   ├── panels/
│   │   ├── agent-panel.tsx       # Already displays agents
│   │   └── retrieval-panel.tsx   # Already displays docs
│   ├── graphs/
│   │   └── execution-graph.tsx   # Already displays workflow
│   ├── metrics/
│   │   └── agent-metrics.tsx     # Already displays tokens/cost
│   ├── modals/
│   │   └── document-modal.tsx    # Already displays doc content
│   └── cards/
│       ├── cache-operation-card.tsx   # Already displays cache hit/miss
│       ├── vector-search-card.tsx     # Already displays similarity
│       └── query-analysis-card.tsx    # Already displays routing
└── providers/
    └── chat-provider.tsx         # Already manages chat state
```

### Testing Strategy

**[Source: architecture/15-testing-strategy.md]**

**Manual QA Required:**
This story focuses on manual testing because:
1. Frontend tests already exist (mock data has same structure)
2. Need to verify real integration works end-to-end
3. SSE streaming hard to test automatically
4. Visual verification needed for UI updates

**Manual Test Checklist:**
- [ ] Test each agent type with appropriate queries
- [ ] Verify all panels update with real data
- [ ] Verify SSE events stream in correct order
- [ ] Verify error handling works
- [ ] Test on multiple browsers
- [ ] Document any issues

**No New Tests Required:**
- Existing component tests already validate rendering
- Existing tests use mock data with same schema as real data
- Integration confirmed via manual QA

### Environment Configuration

**[Source: orchestratai_client/.env.local]**

```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

Verify this environment variable is used in API client.

### Browser Compatibility
**[Source: agent-feature-planning.md:962-975]**

SSE (Server-Sent Events) support:
- Chrome 6+: ✅ Full support
- Firefox 6+: ✅ Full support
- Safari 5+: ✅ Full support
- Edge 79+: ✅ Full support
- Mobile browsers: ✅ Full support

No polyfill needed - native EventSource API widely supported.

### Error Handling
**[Source: Story 4.6 - Error Handling & Fallback]**

Existing error handling should work with real data:
- Network errors: Show user-friendly message
- SSE connection drops: Automatically retry
- Backend errors: Display error response
- Timeout: Show timeout message

No changes needed - already implemented.

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-02 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
claude-sonnet-4-5-20250929

### Debug Log References
(To be filled by dev agent)

### Completion Notes List
- Task 1: SSE event handlers verified - all 4 event types (message_chunk, agent_status, retrieval_log, done) already implemented in use-streaming.ts:303-420. No changes required.
- **BUG FIX**: Fixed ERR_INVALID_CHUNKED_ENCODING in SSE stream proxy (stream/[stream_id]/route.ts:96-131)
  - Issue: Next.js couldn't properly pass backendResponse.body directly
  - Fix: Created ReadableStream with proper reader/controller to forward SSE chunks
  - Now properly streams SSE events from backend through Next.js proxy to browser
- Tasks 2-13: All tasks are **manual testing tasks** requiring backend running. Components already built:
  - AgentPanel (agent-panel.tsx:23-138) - Uses useChatAgents hook to display agent states
  - ChatProvider (chat-provider.tsx) - Manages agent state via React Context
  - All components consume real data from ChatProvider - no mock data hardcoded
  - Ready for manual QA with backend running

### File List
(To be filled by dev agent)

## QA Results
(To be filled by QA agent)
