# <!-- Powered by BMAD™ Core -->

## Status
Draft

## Story
**As a** backend developer,
**I want** Hybrid and Direct agents with a resilience/fallback chain,
**so that** complex queries leverage both retrieval and caching while simple queries get fast responses, with graceful degradation on failures

## Acceptance Criteria
1. Hybrid agent combines cache + retrieval context and reports `sources_used > 1`
2. Direct agent handles unsupported queries with low latency and cost
3. Fallback chain escalates through Hybrid → RAG → CAG → Direct when earlier agents fail, and surfaces the fallback path in metrics/logs
4. Automated tests in `tests/hybrid` and `tests/fallback` pass with ≥90% coverage
5. Manual smoke test confirms users still receive a graceful response even if RAG or CAG throws

## Tasks / Subtasks

- [ ] Task 1: Hybrid agent implementation (AC: 1)
  - [ ] Create `orchestratai_api/src/agents/workers/hybrid_agent.py`
  - [ ] Extend `BaseAgent` from Story 7.3
  - [ ] Inject RAG agent (via dependency container), RedisSemanticCache, embeddings provider, and GPT-4o provider (via ProviderFactory)
  - [ ] Implement parallel retrieval workflow:
    - Create task: `rag_task = asyncio.create_task(self._rag_agent.run(...))`
    - Create task: `cache_task = asyncio.create_task(self._cache.get(embedding=...))`
    - Await both: `rag_result, cache_hit = await asyncio.gather(rag_task, cache_task)`
  - [ ] Merge contexts:
    - Collect documents from RAG result
    - If cache hit, extract cached context
    - Deduplicate by `source + page`
    - Rank by relevance (similarity scores)
  - [ ] Call GPT-4o provider with merged context
  - [ ] Aggregate metrics:
    - `retrieval_latency`: RAG agent latency
    - `cache_latency`: Cache lookup latency
    - `total_tokens`: Sum of all tokens
    - `sources_used`: Count of unique sources (RAG + cache)
  - [ ] Return `ChatResponse` with rich context
  - [ ] Include both VECTOR_SEARCH and CACHE logs in retrieval_logs

- [ ] Task 2: Direct agent implementation (AC: 2)
  - [ ] Create `orchestratai_api/src/agents/workers/direct_agent.py`
  - [ ] Extend `BaseAgent`
  - [ ] Resolve Bedrock Claude 3 Haiku provider via `ProviderFactory`
  - [ ] Implement simple workflow:
    - Call provider with query (no retrieval, no cache)
    - Return conversational response
  - [ ] Return `ChatResponse` with message
  - [ ] Return `AgentMetrics` with minimal cost (<$0.001)
  - [ ] Target latency < 1 second
  - [ ] No retrieval logs (direct conversation)

- [ ] Task 3: Fallback chain implementation (AC: 3)
  - [ ] Update `orchestratai_api/src/agents/orchestrator.py`
  - [ ] Add `attempted_agents: list[str]` to `OrchestratorState`
  - [ ] Create helper: `async def execute_with_fallback(preferred: list[Callable])`
  - [ ] Iterate through agents in order
  - [ ] Wrap each agent call in try/except
  - [ ] On exception:
    - Log error with agent name
    - Append to `attempted_agents`
    - Emit `LogType.ROUTING` log with failure message
    - Try next agent in chain
  - [ ] Fallback order: Hybrid → RAG → CAG → Direct
  - [ ] If all fail, return error response with all attempted agents
  - [ ] Update metrics to include `success: bool` and `error_message: str | None`
  - [ ] Emit fallback events via SSE

- [ ] Task 4: Routing rules (AC: 1, 2)
  - [ ] Update `decide_route` in orchestrator
  - [ ] Add intent detection:
    - `COMPLEX_QUESTION`: Multi-step queries, technical deep-dives → Hybrid
    - `SIMPLE_CHAT`: Greetings, small talk → Direct
    - `DOMAIN_QUESTION`: Knowledge lookups → RAG
    - `POLICY_QUESTION`: Policies, billing → CAG
  - [ ] Use heuristics for classification:
    - Message length > 100 chars → likely complex
    - Keywords: "explain", "compare", "analyze" → complex
    - Keywords: "hello", "thanks", "bye" → simple chat
  - [ ] Update conditional edges to route to all 4 agents
  - [ ] Ensure state tracks which agent was selected

- [ ] Task 5: Unit tests (AC: 4)
  - [ ] Create `tests/hybrid/__init__.py`
  - [ ] Create `tests/hybrid/test_hybrid_agent.py`
  - [ ] Mock RAG agent responses
  - [ ] Mock cache responses
  - [ ] Test parallel execution (asyncio.gather)
  - [ ] Test context deduplication:
    - RAG returns doc A, B, C
    - Cache returns doc B, D
    - Verify merged context: A, B, C, D (B not duplicated)
  - [ ] Test metrics aggregation:
    - Verify sources_used = 4
    - Verify retrieval_latency + cache_latency tracked
  - [ ] Create `tests/hybrid/test_direct_agent.py`
  - [ ] Mock Bedrock Haiku provider
  - [ ] Test latency < 1 second
  - [ ] Test cost < $0.001 (using pricing helper)
  - [ ] Test no retrieval logs emitted
  - [ ] Create `tests/fallback/__init__.py`
  - [ ] Create `tests/fallback/test_fallback_chain.py`
  - [ ] Mock agent failures (raise exceptions)
  - [ ] Test fallback order: Hybrid fails → RAG called
  - [ ] Test RAG fails → CAG called
  - [ ] Test CAG fails → Direct called (always succeeds)
  - [ ] Test all agents fail → error response with attempted_agents list
  - [ ] Test fallback logs emitted (LogType.ROUTING) and SSE fallback event
  - [ ] Achieve ≥90% coverage

- [ ] Task 6: Integration tests (AC: 4, 5)
  - [ ] Create `tests/hybrid/test_hybrid_integration.py`
  - [ ] Use real ChromaDB and Redis
  - [ ] Test end-to-end hybrid flow:
    - Send complex query
    - Verify both RAG and cache invoked
    - Verify contexts merged
    - Verify GPT-4o called
  - [ ] Create `tests/fallback/test_fallback_integration.py`
  - [ ] Simulate RAG failure (force exception)
  - [ ] Send query that would normally go to RAG
  - [ ] Verify fallback to next agent
  - [ ] Verify attempted_agents list populated
  - [ ] Verify user still gets response
  - [ ] Clean up test data
  - [ ] Achieve ≥90% coverage

- [ ] Task 7: Manual smoke testing (AC: 5)
  - [ ] Start all services: `docker compose up`
  - [ ] Start backend: `uv run uvicorn orchestratai_api.src.main:app --reload`
  - [ ] Test Hybrid agent:
    - Query: "Compare RAG and CAG approaches and explain when to use each"
    - Verify Hybrid agent invoked
    - Verify sources_used > 1
    - Verify both VECTOR_SEARCH and CACHE logs
  - [ ] Test Direct agent:
    - Query: "Hello, how are you?"
    - Verify Direct agent invoked
    - Verify fast response (<1s)
    - Verify low cost
  - [ ] Test fallback chain:
    - Temporarily disable ChromaDB
    - Send domain question
    - Verify fallback to CAG or Direct
    - Verify user gets graceful response
    - Re-enable ChromaDB
  - [ ] Document any issues in debug log

## Dev Notes

### Architecture Context
**[Source: docs/agent-planning/agent-feature-planning.md, Story 7.5]**

Deliver the remaining worker agents and the resilience layer. The Hybrid agent combines retrieval + cache signals (parallelised with `asyncio.gather`), while the Direct agent provides a fast fallback for small-talk/unsupported queries. This story also wires in the orchestrator fallback chain (Hybrid → RAG → CAG → Direct) so failures degrade gracefully.

### Hybrid Agent Workflow
**[Source: agent-feature-planning.md:902-911]**

Run RAG retrieval and semantic cache lookup concurrently:

```python
rag_task = asyncio.create_task(self._rag_agent.run(message, session_id=session_id))
cache_task = asyncio.create_task(self._cache.get(embedding=query_embedding))
rag_result, cache_hit = await asyncio.gather(rag_task, cache_task)
```

Merge contexts by ranking unique chunks (deduplicate by `source + page`) and feed into GPT-4o.

Aggregate metrics from both sources (`retrieval_latency`, `cache_latency`, token totals).

### Context Deduplication
**[Source: agent-feature-planning.md:909-911]**

```python
def deduplicate_sources(rag_docs: list[Document], cache_docs: list[Document]) -> list[Document]:
    """Merge and deduplicate by source + page."""
    seen = set()
    merged = []

    for doc in rag_docs + cache_docs:
        key = (doc.metadata.get("source"), doc.metadata.get("page"))
        if key not in seen:
            seen.add(key)
            merged.append(doc)

    return merged
```

Rank by similarity scores (if available) to prioritize most relevant sources.

### Direct Agent Implementation
**[Source: agent-feature-planning.md:913-916]**

Thin wrapper around Bedrock Haiku:

```python
class DirectAgent(BaseAgent):
    async def run(self, request: ChatRequest, **kwargs) -> ChatResponse:
        start = time.perf_counter()
        result = await self.provider.complete(
            messages=[{"role": "user", "content": request.message}]
        )
        metrics = await self._record(start=start, result=result)
        return ChatResponse(message=result.content, metrics=metrics, retrieval_logs=[])
```

Used for chit-chat, unknown intents, or final fallback when other agents fail.

### Fallback Chain
**[Source: agent-feature-planning.md:918-926]**

```python
async def execute_with_fallback(preferred: list[Callable]) -> ChatResponse:
    attempted = []

    for agent_fn in preferred:
        try:
            result = await agent_fn()
            result.metadata["attempted_agents"] = attempted
            return result
        except Exception as e:
            attempted.append(agent_fn.__name__)
            log_error(f"{agent_fn.__name__} failed: {e}")
            # Emit ROUTING log with failure
            continue

    # All failed - return error response
    raise RuntimeError(f"All agents failed: {attempted}")
```

Ensure metrics mark failures (`success=False`, `error_message`) for transparency.

### Routing Rules
**[Source: agent-feature-planning.md:928-933]**

Update `decide_route` to detect multi-step/technical queries:

```python
def decide_route(state: OrchestratorState) -> str:
    intent = state["analysis"]["intent"]
    message = state["messages"][-1]["content"]

    # Heuristics for complexity
    is_complex = (
        len(message) > 100
        or any(kw in message.lower() for kw in ["explain", "compare", "analyze", "how does"])
    )

    if intent == "META_QUESTION":
        return "guide"
    elif is_complex or intent == "COMPLEX_QUESTION":
        return "delegate_hybrid"
    elif intent == "DOMAIN_QUESTION":
        return "delegate_rag"
    elif intent in ["POLICY_QUESTION", "PRICING_QUESTION"]:
        return "delegate_cag"
    else:
        return "delegate_direct"
```

### File Structure
**[Source: architecture/source-tree.md]**

```
orchestratai_api/src/
├── agents/
│   ├── orchestrator.py        # UPDATE: Add fallback chain
│   └── workers/
│       ├── hybrid_agent.py    # NEW: Hybrid agent
│       └── direct_agent.py    # NEW: Direct agent

orchestratai_api/tests/
├── hybrid/
│   ├── __init__.py
│   ├── test_hybrid_agent.py            # NEW: Hybrid unit tests
│   └── test_hybrid_integration.py      # NEW: Hybrid integration tests
└── fallback/
    ├── __init__.py
    ├── test_fallback_chain.py          # NEW: Fallback unit tests
    └── test_fallback_integration.py    # NEW: Fallback integration tests
```

### Testing

**[Source: architecture/15-testing-strategy.md]**

**Test File Locations:**
- `orchestratai_api/tests/hybrid/test_hybrid_agent.py`
- `orchestratai_api/tests/hybrid/test_hybrid_integration.py`
- `orchestratai_api/tests/hybrid/test_direct_agent.py`
- `orchestratai_api/tests/fallback/test_fallback_chain.py`
- `orchestratai_api/tests/fallback/test_fallback_integration.py`

**Testing Framework:**
- pytest + pytest-asyncio
- Mock agent responses for unit tests
- Real ChromaDB + Redis for integration tests
- Force exceptions to test fallback paths

**Test Coverage Requirements:**
- Minimum 90% coverage required
- Test context deduplication logic
- Test parallel execution with asyncio.gather
- Test fallback chain order
- Test graceful degradation

**Example Test Structure:**
```python
import pytest

@pytest.mark.asyncio
async def test_fallback_chain(orchestrator, monkeypatch):
    async def failing_run(self, message, session_id):  # pragma: no cover - test helper
        raise RuntimeError("boom")

    monkeypatch.setattr(RAGAgent, "run", failing_run)
    response = await orchestrator.ainvoke({"messages": [{"role": "user", "content": "Need help"}]})
    assert response["result"].agents[-1].id in {AgentId.CAG.value, AgentId.DIRECT.value}
    assert response["result"].fallback_from == ["rag"]
```

### Environment Variables
**[Source: agent-feature-planning.md:367-377]**

```bash
# Worker agent models:
DEFAULT_HYBRID_MODEL=gpt-4o
DEFAULT_DIRECT_MODEL=anthropic.claude-3-haiku-20240307-v1:0
```

### Python Dependencies

All dependencies already added in previous stories:
- `asyncio` (standard library)
- `openai` (Story 7.1)
- `boto3` (Story 7.1)

### Metrics Aggregation Example

For Hybrid agent combining RAG + Cache:

```python
{
  "agent_id": "hybrid",
  "provider": "openai",
  "model": "gpt-4o",
  "tokens_input": 2500,  # Context from RAG + cache
  "tokens_output": 800,
  "cost_total": 0.0205,  # (2500/1M × $5) + (800/1M × $15)
  "latency_ms": 2800,
  "extra": {
    "sources_used": 7,  # 5 from RAG, 2 from cache (deduplicated)
    "retrieval_latency_ms": 1200,
    "cache_latency_ms": 45
  }
}
```

### Fallback Event Example

When RAG fails and fallback to CAG:

```python
{
  "type": "ROUTING",
  "message": "RAG agent failed: ChromaDB connection error. Falling back to CAG agent.",
  "agent_attempted": "rag",
  "fallback_to": "cag",
  "error": "ChromaDB connection error",
  "timestamp": 1234567890.123
}
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-02 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
(To be filled by dev agent)

### Debug Log References
(To be filled by dev agent)

### Completion Notes List
(To be filled by dev agent)

### File List
(To be filled by dev agent)

## QA Results
(To be filled by QA agent)
